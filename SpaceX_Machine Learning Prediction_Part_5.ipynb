{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n",
    "## Hands on Lab: Complete the Machine Learning Prediction lab\n",
    "Estimated time needed: **60** minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space X advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars; other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. Therefore if we can determine if the first stage will land, we can determine the cost of a launch. This information can be used if an alternate company wants to bid against space X for a rocket launch.   In this lab, you will create a machine learning pipeline  to predict if the first stage will land given the data from the preceding labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing_1.gif)\n",
    "Several examples of an unsuccessful landing are shown here:\n",
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n",
    "Most unsuccessful landings are planed. Space X; performs a controlled landing in the oceans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "Perform exploratory  Data Analysis and determine Training Labels\n",
    "*   create a column for the class\n",
    "*   Standardize the data\n",
    "*   Split into training data and test data\n",
    "-Find best Hyperparameter for SVM, Classification Trees and Logistic Regression\n",
    "*   Find the method performs best using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piplite\n",
    "await piplite.install(['numpy'])\n",
    "await piplite.install(['pandas'])\n",
    "await piplite.install(['seaborn'])\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y, y_predict):\n",
    "    \"this function plots the confusion matrix\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y, y_predict)\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['did not land', 'land'])\n",
    "    ax.yaxis.set_ticklabels(['did not land', 'landed'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from js import fetch\n",
    "import io\n",
    "URL1 = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv\"\n",
    "resp1 = await fetch(URL1)\n",
    "text1 = io.BytesIO((await resp1.arrayBuffer()).to_py())\n",
    "data = pd.read_csv(text1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL2 = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv'\n",
    "resp2 = await fetch(URL2)\n",
    "text2 = io.BytesIO((await resp2.arrayBuffer()).to_py())\n",
    "X = pd.read_csv(text2)\n",
    "X.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  1\n",
    "Create a NumPy array from the column <code>Class</code> in <code>data</code>, by applying the method <code>to_numpy()</code>  then\n",
    "assign it  to the variable <code>Y</code>,make sure the output is a  Pandas series (only one bracket df['name of  column'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['Class'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  2\n",
    "Standardize the data in <code>X</code> then reassign it to the variable  <code>X</code> using the transform provided below.\n",
    "# students get this \n",
    "transform = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  3\n",
    "Use the function train_test_split to split the data X and Y into training and test data. Set the parameter test_size to  0.2 and random_state to 2. The training data and test data should be assigned to the following labels.\n",
    "<code>X_train, X_test, Y_train, Y_test</code>\n",
    "we can see we only have 18 test samples.\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  4\n",
    "Create a logistic regression object  then create a  GridSearchCV object  <code>logreg_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[0.01,0.1,1], 'penalty':['l2'], 'solver':['lbfgs']}\n",
    "lr = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(lr, parameters, cv=10)\n",
    "logreg_cv.fit(X_train, Y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \", logreg_cv.best_params_)\n",
    "print(\"accuracy :\", logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  5\n",
    "Calculate the accuracy on the test data using the method <code>score</code>:\n",
    "Lets look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = logreg_cv.predict(X_test)\n",
    "print(\"Test accuracy:\", logreg_cv.score(X_test, Y_test))\n",
    "plot_confusion_matrix(Y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "True Postive - 12 (True label is landed, Predicted label is also landed)\n",
    "False Postive - 3 (True label is not landed, Predicted label is landed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  6\n",
    "Create a support vector machine object then  create a  <code>GridSearchCV</code> object  <code>svm_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf','poly','rbf', 'sigmoid'), 'C': np.logspace(-3, 3, 5), 'gamma':np.logspace(-3, 3, 5)}\n",
    "svm = SVC()\n",
    "svm_cv = GridSearchCV(svm, parameters, cv=10)\n",
    "svm_cv.fit(X_train, Y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \", svm_cv.best_params_)\n",
    "print(\"accuracy :\", svm_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  7\n",
    "Calculate the accuracy on the test data using the method <code>score</code>:\n",
    "We can plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = svm_cv.predict(X_test)\n",
    "print(\"Test accuracy:\", svm_cv.score(X_test, Y_test))\n",
    "plot_confusion_matrix(Y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  8\n",
    "Create a decision tree classifier object then  create a  <code>GridSearchCV</code> object  <code>tree_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "     'splitter': ['best', 'random'],\n",
    "     'max_depth': [2*n for n in range(1,10)],\n",
    "     'max_features': ['auto', 'sqrt'],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10]}\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = GridSearchCV(tree, parameters, cv=10)\n",
    "tree_cv.fit(X_train, Y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \", tree_cv.best_params_)\n",
    "print(\"accuracy :\", tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  9\n",
    "Calculate the accuracy of tree_cv on the test data using the method <code>score</code>:\n",
    "We can plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = tree_cv.predict(X_test)\n",
    "print(\"Test accuracy:\", tree_cv.score(X_test, Y_test))\n",
    "plot_confusion_matrix(Y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  10\n",
    "Create a k nearest neighbors object then  create a  <code>GridSearchCV</code> object  <code>knn_cv</code> with cv = 10.  Fit the object to find the best parameters from the dictionary <code>parameters</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1,2]}\n",
    "KNN = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(KNN, parameters, cv=10)\n",
    "knn_cv.fit(X_train, Y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \", knn_cv.best_params_)\n",
    "print(\"accuracy :\", knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  11\n",
    "Calculate the accuracy of knn_cv on the test data using the method <code>score</code>:\n",
    "We can plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = knn_cv.predict(X_test)\n",
    "print(\"Test accuracy:\", knn_cv.score(X_test, Y_test))\n",
    "plot_confusion_matrix(Y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK  12\n",
    "Find the method performs best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test accuracies\n",
    "test_accuracies = {\n",
    "    'Logistic Regression': logreg_cv.score(X_test, Y_test),\n",
    "    'SVM': svm_cv.score(X_test, Y_test),\n",
    "    'Decision Tree': tree_cv.score(X_test, Y_test),\n",
    "    'KNN': knn_cv.score(X_test, Y_test)\n",
    "}\n",
    "print(\"Test Accuracies:\", test_accuracies)\n",
    "best_method = max(test_accuracies, key=test_accuracies.get)\n",
    "print(\"Best performing method:\", best_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "[Pratiksha Verma](https://www.linkedin.com/in/pratiksha-verma-6487561b1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log--!>\n",
    "<!--| Date (YYYY-MM-DD) | Version | Changed By      | Change Description      |\n",
    "| ----------------- | ------- | -------------   | ----------------------- |\n",
    "| 2022-11-09        | 1.0     | Pratiksha Verma | Converted initial version to Jupyterlite|--!>\n",
    "### <h3 align=\"center\"> IBM Corporation 2022. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
