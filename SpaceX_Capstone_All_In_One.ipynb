{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page 6: Data Collection\n",
    "## How Data Sets Were Collected\n",
    "\n",
    "This project uses two main sources for SpaceX Falcon 9 launch data:\n",
    "\n",
    "1. **SpaceX API**\n",
    "    - Used Python's `requests` library to access the SpaceX REST API endpoint: `https://api.spacexdata.com/v4/launches/past`\n",
    "    - Data returned in JSON format, parsed and loaded into Pandas DataFrame for analysis.\n",
    "    - API provides detailed launch records including flight number, launch site, payload, orbit, customer, and landing outcome.\n",
    "\n",
    "2. **Wikipedia Web Scraping**\n",
    "    - Used Python's `requests` and `BeautifulSoup` libraries to scrape the Falcon 9 and Falcon Heavy launches table from Wikipedia.\n",
    "    - Extracted columns: Flight No., Launch site, Payload, Payload mass, Orbit, Customer, Launch outcome, Booster version, Booster landing, Date, Time.\n",
    "    - Data cleaned and loaded into Pandas DataFrame for further wrangling and analysis.\n",
    "\n",
    "### Data Collection Process Flowchart\n",
    "\n",
    "Below is a simple flowchart (as an image) showing the data collection workflow. *(If you want to use a diagram tool, you can create a similar flowchart and insert the image here.)*\n",
    "\n",
    "![Data Collection Flowchart](https://raw.githubusercontent.com/ali-ezz/the-final-project-of-course-Applied-Data-Science-Capstone/main/assets/data_collection_flowchart.png)\n",
    "\n",
    "If you do not have an image, here is a text version of the flow:\n",
    "\n",
    "```\n",
    "Start\n",
    "│\n",
    "├── SpaceX API Call\n",
    "│      │\n",
    "│      └── Parse JSON to DataFrame\n",
    "│\n",
    "├── Wikipedia Scraping\n",
    "│      │\n",
    "│      └── Extract Table to DataFrame\n",
    "│\n",
    "└── Combine & Clean Data\n",
    "       │\n",
    "       └── Ready for Wrangling & Analysis\n",
    "```\n",
    "\n",
    "### Key Phrases\n",
    "- Automated data retrieval using REST API and web scraping.\n",
    "- Unified launch records from multiple sources.\n",
    "- Data prepared for wrangling, EDA, SQL, mapping, dashboarding, and machine learning.\n",
    "\n",
    "*(Add a screenshot of your flowchart or process diagram here if needed)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
